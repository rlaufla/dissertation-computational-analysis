{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0780a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kiwipiepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5516ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "\n",
    "kiwi = Kiwi()\n",
    ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143f4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from kiwipiepy import Kiwi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rc('font', family='Malgun Gothic')  # Windows용 기본 한글 글꼴\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False  # 마이너스 기호 깨짐 방지\n",
    "\n",
    "# ===================== 사용자 설정 =====================\n",
    "base_dir = r\"C:\\Users\\논문\"\n",
    "senti_path = os.path.join(base_dir, \"for the analysing\", \"data\", \"SentiWord_info.json\")\n",
    "input_files = [\n",
    "    (\"type3_스크린미디어기사.txt\", \"screen_media\"),\n",
    "    (\"non_screen_media.txt\", \"non_screenmedia\"),\n",
    "]\n",
    "output_dir = os.path.join(base_dir, \"3\", \"분석결과\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# =====================================================\n",
    "\n",
    "# 감성사전 로드\n",
    "with open(senti_path, encoding='utf-8-sig') as f:\n",
    "    senti_dict = json.load(f)\n",
    "senti_lookup = {item['word']: int(item['polarity']) for item in senti_dict}\n",
    "\n",
    "# KIWI 초기화\n",
    "kiwi = Kiwi()\n",
    "\n",
    "records = []\n",
    "\n",
    "for filename, label in input_files:\n",
    "    filepath = os.path.join(base_dir, \"3\", filename)\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    tokens = kiwi.tokenize(text)\n",
    "\n",
    "    for token in tokens:\n",
    "        word = token.form\n",
    "        tag = token.tag\n",
    "        if tag.startswith(\"VV\") or tag.startswith(\"VA\"):\n",
    "            word += \"다\"\n",
    "        if word in senti_lookup:\n",
    "            score = senti_lookup[word]\n",
    "            records.append({\n",
    "                \"파일\": filename,\n",
    "                \"유형\": label,\n",
    "                \"단어\": word,\n",
    "                \"극성\": score\n",
    "            })\n",
    "\n",
    "# DataFrame 구성 및 저장\n",
    "sent_df = pd.DataFrame(records)\n",
    "sent_df.to_csv(os.path.join(output_dir, \"감성단어_기록.csv\"), index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "# 유형 이름 영어로 바꾸기\n",
    "type_mapping = {\n",
    "    \"screen_media\": \"articles on screen media\",\n",
    "    \"non_screenmedia\": \"straight articles\",\n",
    "       \n",
    "}\n",
    "sent_df[\"type\"] = sent_df[\"유형\"].map(type_mapping)\n",
    "\n",
    "# 평균 감정 점수 계산 및 시각화\n",
    "avg_df = sent_df.groupby(\"type\")[\"극성\"].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=avg_df, x=\"type\", y=\"극성\", palette=\"Set2\", width=0.5)  # width로 바 두께 조절\n",
    "plt.axhline(0, color='gray', linestyle='--')\n",
    "plt.title(\"Average Sentiment Score by Type\")\n",
    "plt.ylabel(\"Average Sentiment Score\")\n",
    "plt.xlabel(\"Type\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"avg_sentiment_score_by_type.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b76fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfab79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\논문\\3\\coding.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# [2] type → media_type 매핑\n",
    "def classify_media_type(t):\n",
    "    if t in [1, 2]:\n",
    "        return 'non screen media'\n",
    "    elif t == 3:\n",
    "        return 'screen media'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "df['media_type'] = df['Type'].apply(classify_media_type)\n",
    "\n",
    "# [3] 그룹별 점수 추출\n",
    "non_screen = df[df['media_type'] == 'non screen media']['평균감성점수']\n",
    "screen = df[df['media_type'] == 'screen media']['평균감성점수']\n",
    "\n",
    "# [4] 샘플 수 확인\n",
    "print(f\"\\n샘플 수 - non screen: {len(non_screen)}, screen: {len(screen)}\")\n",
    "\n",
    "# 조건: screen media의 샘플 수가 너무 작으면 비모수 검정으로 강제\n",
    "if len(screen) < 10 or len(non_screen) < 10:\n",
    "    # 보수적으로 Mann-Whitney로 처리\n",
    "    stat, p = mannwhitneyu(non_screen, screen, alternative='two-sided')\n",
    "    print(\"  → [샘플 수 적음] Mann-Whitney U test 적용\")\n",
    "\n",
    "# [5] 정규성 검정\n",
    "stat_ns, p_ns = shapiro(non_screen)\n",
    "stat_s, p_s = shapiro(screen)\n",
    "print(f\"\\n[정규성 검정 - Shapiro-Wilk]\")\n",
    "print(f\"  non screen media: p = {p_ns:.4f}\")\n",
    "print(f\"  screen media    : p = {p_s:.4f}\")\n",
    "\n",
    "# [6] 등분산성 검정\n",
    "stat_lev, p_lev = levene(non_screen, screen)\n",
    "print(f\"\\n[등분산성 검정 - Levene]\")\n",
    "print(f\"  p = {p_lev:.4f}\")\n",
    "\n",
    "# [7] 통계적 비교\n",
    "print(\"\\n[통계적 비교]\")\n",
    "\n",
    "if len(screen) < 10 or len(non_screen) < 10:\n",
    "    stat, p = mannwhitneyu(non_screen, screen, alternative='two-sided')\n",
    "    print(\"  → [샘플 수 적음] Mann-Whitney U test 적용\")\n",
    "elif p_ns > 0.05 and p_s > 0.05:\n",
    "    if p_lev > 0.05:\n",
    "        stat, p = ttest_ind(non_screen, screen, equal_var=True)\n",
    "        print(\"  → Student's t-test 적용\")\n",
    "    else:\n",
    "        stat, p = ttest_ind(non_screen, screen, equal_var=False)\n",
    "        print(\"  → Welch's t-test 적용\")\n",
    "else:\n",
    "    stat, p = mannwhitneyu(non_screen, screen, alternative='two-sided')\n",
    "    print(\"  → Mann-Whitney U test 적용 (정규성 불만족)\")\n",
    "\n",
    "print(f\"  통계량 = {stat:.4f}, p-value = {p:.4f}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "# unknown 행 제거\n",
    "summary_table_cleaned = summary_table[summary_table['media_type'] != 'unknown']\n",
    "display(summary_table_cleaned)\n",
    "\n",
    "# Boxplot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(data=df, x='media_type', y='평균감성점수')\n",
    "plt.title(\"Boxplot: 평균 감성점수 by Media Type\")\n",
    "plt.xlabel(\"Media Type\")\n",
    "plt.ylabel(\"평균 감성점수\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 저장 (논문용)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"boxplot_sentiment.png\", dpi=300)\n",
    "\n",
    "\n",
    "# Q-Q Plot (non screen)\n",
    "plt.figure(figsize=(6, 4))\n",
    "stats.probplot(non_screen, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q Plot: Non Screen Media\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 저장 (논문용)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"boxplot_sentiment.png\", dpi=300)\n",
    "\n",
    "\n",
    "# Q-Q Plot (screen)\n",
    "plt.figure(figsize=(6, 4))\n",
    "stats.probplot(screen, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q Plot: Screen Media\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# 저장 (논문용)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"boxplot_sentiment.png\", dpi=300)\n",
    "\n",
    "# type별 감성점수 통계 요약표\n",
    "summary_table = df.groupby('media_type')['평균감성점수'].agg(\n",
    "    N = 'count',\n",
    "    Mean = 'mean',\n",
    "    Median = 'median',\n",
    "    SD = 'std',\n",
    "    Min = 'min',\n",
    "    Max = 'max'\n",
    ").reset_index()\n",
    "\n",
    "# 보기 좋게 반올림\n",
    "summary_table = summary_table.round(4)\n",
    "\n",
    "# 출력\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "display(summary_table)\n",
    "\n",
    "# 저장\n",
    "summary_table.to_excel(\"sentiment_summary_by_type.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c69a443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "# 1. 파일 경로\n",
    "data_path = r\"C:\\Users\\논문\\3\\coding.xlsx\"\n",
    "senti_dict_path = r\"C:\\Users\\논문\\data\\SentiWord_info.json\"\n",
    "\n",
    "# 2. 데이터 불러오기\n",
    "df = pd.read_excel(data_path)\n",
    "\n",
    "# 3. 감성사전 불러오기\n",
    "with open(senti_dict_path, 'r', encoding='utf-8-sig') as f:\n",
    "    senti_dict = json.load(f)\n",
    "\n",
    "# 감성어 → 점수 딕셔너리 만들기 (예: {'기쁘다': 0.7, '싫다': -0.5, ...})\n",
    "senti_score_dict = {entry['word']: float(entry['polarity']) for entry in senti_dict}\n",
    "\n",
    "# 4. 형태소 분석기 초기화\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# 5. 분석 결과 저장용 리스트\n",
    "results = []\n",
    "\n",
    "# 6. 각 기사 분석\n",
    "for idx, row in df.iterrows():\n",
    "    article_id = row['ID']\n",
    "    article_type = row['Type']\n",
    "    text = str(row['본문내용'])\n",
    "\n",
    "    # 전체 단어 수 계산 (공백 기준)\n",
    "    total_words = len(text.split())\n",
    "\n",
    "    # 형태소 분석\n",
    "    tokens = kiwi.tokenize(text)\n",
    "\n",
    "    # 감성 단어 필터링\n",
    "    sentiment_words = []\n",
    "    pos_count, neg_count = 0, 0\n",
    "    sentiment_score_sum = 0\n",
    "\n",
    "    for token in tokens:\n",
    "        word = token.form\n",
    "        if word in senti_score_dict:\n",
    "            score = senti_score_dict[word]\n",
    "            sentiment_words.append(word)\n",
    "            sentiment_score_sum += score\n",
    "            if score > 0:\n",
    "                pos_count += 1\n",
    "            elif score < 0:\n",
    "                neg_count += 1\n",
    "\n",
    "    # 결과 계산\n",
    "    sentiment_count = len(sentiment_words)\n",
    "    avg_sentiment = sentiment_score_sum / sentiment_count if sentiment_count > 0 else 0\n",
    "    senti_ratio = sentiment_count / total_words if total_words > 0 else 0\n",
    "\n",
    "    results.append({\n",
    "        '파일': article_id,\n",
    "        '유형': article_type,\n",
    "        '전체단어수': total_words,\n",
    "        '감성단어수': sentiment_count,\n",
    "        '평균감성점수': round(avg_sentiment, 4),\n",
    "        '긍정단어수': pos_count,\n",
    "        '부정단어수': neg_count,\n",
    "        '감성단어비율': round(senti_ratio, 4)\n",
    "    })\n",
    "\n",
    "# 7. DataFrame 변환 후 엑셀 저장\n",
    "result_df = pd.DataFrame(results)\n",
    "result_df.to_excel(\"감성분석_자동계산결과.xlsx\", index=False)\n",
    "print(\"✅ 감성 분석 결과 저장 완료: 감성분석_자동계산결과.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c3ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kiwipiepy import Kiwi\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows용 폰트\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ===================== 사용자 설정 =====================\n",
    "base_dir = r\"C:\\Users\\논문\"\n",
    "senti_path = os.path.join(base_dir, \"for the analysing\", \"data\", \"SentiWord_info.json\")\n",
    "input_files = [\n",
    "    (\"non_screen_media.txt\", \"articles_not_onvisualmedia\"),\n",
    "    (\"type3_스크린미디어기사.txt\", \"on_screenmedia\"),\n",
    "]\n",
    "output_dir = os.path.join(base_dir, \"3\", \"분석결과\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# =====================================================\n",
    "\n",
    "# 감성사전 로드\n",
    "with open(senti_path, encoding='utf-8-sig') as f:\n",
    "    senti_dict = json.load(f)\n",
    "senti_lookup = {item['word']: int(item['polarity']) for item in senti_dict}\n",
    "\n",
    "# KIWI 초기화\n",
    "kiwi = Kiwi()\n",
    "\n",
    "records = []\n",
    "summary_stats = []\n",
    "\n",
    "for filename, label in input_files:\n",
    "    filepath = os.path.join(base_dir, \"3\", filename)\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    tokens = kiwi.tokenize(text)\n",
    "\n",
    "    senti_scores = []\n",
    "    total_tokens = len(tokens)\n",
    "\n",
    "    for token in tokens:\n",
    "        word = token.form\n",
    "        tag = token.tag\n",
    "        if tag.startswith(\"VV\") or tag.startswith(\"VA\"):\n",
    "            word += \"다\"\n",
    "        if word in senti_lookup:\n",
    "            score = senti_lookup[word]\n",
    "            senti_scores.append(score)\n",
    "            records.append({\n",
    "                \"파일\": filename,\n",
    "                \"유형\": label,\n",
    "                \"단어\": word,\n",
    "                \"극성\": score\n",
    "            })\n",
    "\n",
    "    senti_count = len(senti_scores)\n",
    "    avg_score = np.mean(senti_scores) if senti_count else 0\n",
    "    pos_count = sum(1 for s in senti_scores if s > 0)\n",
    "    neg_count = sum(1 for s in senti_scores if s < 0)\n",
    "    ratio = (senti_count / total_tokens * 100) if total_tokens else 0\n",
    "\n",
    "    summary_stats.append({\n",
    "        \"파일\": filename,\n",
    "        \"유형\": label,\n",
    "        \"전체단어수\": total_tokens,\n",
    "        \"감성단어수\": senti_count,\n",
    "        \"평균감정점수\": round(avg_score, 3),\n",
    "        \"긍정단어수\": pos_count,\n",
    "        \"부정단어수\": neg_count,\n",
    "        \"감성단어비율\": round(ratio, 2)\n",
    "    })\n",
    "\n",
    "# DataFrame 구성 및 저장\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(os.path.join(output_dir, \"감성단어_기록0703.csv\"), index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 긍/부정 단어만 필터링 및 저장\n",
    "positive_df = df[df[\"극성\"] > 0]\n",
    "negative_df = df[df[\"극성\"] < 0]\n",
    "positive_df.to_csv(os.path.join(output_dir, \"긍정단어_기록0703.csv\"), index=False, encoding='utf-8-sig')\n",
    "negative_df.to_csv(os.path.join(output_dir, \"부정단어_기록0703.csv\"), index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 감성 단어 개수 요약 저장\n",
    "summary_df = df.groupby([\"유형\", \"극성\"]).size().unstack(fill_value=0).reset_index()\n",
    "summary_df.to_csv(os.path.join(output_dir, \"감성단어_개수요약0703.csv\"), index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 유형별 평균 감정 점수 시각화 (전체 제외)\n",
    "plot_df = df[df[\"유형\"] != \"전체\"]\n",
    "avg_df = plot_df.groupby(\"유형\")[\"극성\"].mean().reset_index()\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=avg_df, x=\"유형\", y=\"극성\", palette=\"Set2\")\n",
    "plt.axhline(0, color='gray', linestyle='--')\n",
    "plt.title(\"기사 유형별 평균 감성 점수\")\n",
    "plt.ylabel(\"평균 감성 점수\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"유형별_평균감성점수0703.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 종합 요약 통계 저장\n",
    "summary_stats_df = pd.DataFrame(summary_stats)\n",
    "summary_stats_df.to_csv(os.path.join(output_dir, \"감성_요약통계0703.csv\"), index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 유형별 긍정단어 Top 20 시각화\n",
    "for label in df['유형'].unique():\n",
    "    if label == \"전체\":\n",
    "        continue\n",
    "    pos_top = positive_df[positive_df['유형'] == label]['단어'].value_counts().head(20)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=pos_top.values, y=pos_top.index, palette=\"Greens_r\")\n",
    "    plt.title(f\"[{label}] 긍정 단어 Top 20\")\n",
    "    plt.xlabel(\"빈도\")\n",
    "    plt.ylabel(\"단어\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{label}_긍정단어_TOP20_0703.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# 유형별 부정단어 Top 20 시각화\n",
    "for label in df['유형'].unique():\n",
    "    if label == \"전체\":\n",
    "        continue\n",
    "    neg_top = negative_df[negative_df['유형'] == label]['단어'].value_counts().head(20)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=neg_top.values, y=neg_top.index, palette=\"Reds_r\")\n",
    "    plt.title(f\"[{label}] 부정 단어 Top 20\")\n",
    "    plt.xlabel(\"빈도\")\n",
    "    plt.ylabel(\"단어\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{label}_부정단어_TOP20_0703.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1bba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "# 엑셀 파일 경로\n",
    "file_path = r\"C:\\Users\\논문\\3\\coding.xlsx\"\n",
    "\n",
    "# 엑셀에서 데이터 불러오기\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 필요한 열만 필터링 (예: media_type, 평균감성점수)\n",
    "# media_type: 1 = non-screen, 2 = screen\n",
    "\n",
    "group1 = df[df[\"Type\"] == 1][\"평균감성점수\"].dropna().tolist()\n",
    "group2 = df[df[\"Type\"] == 2][\"평균감성점수\"].dropna().tolist()\n",
    "\n",
    "# Cliff's delta 계산 함수\n",
    "def cliffs_delta(lst1, lst2):\n",
    "    n1, n2 = len(lst1), len(lst2)\n",
    "    gt = sum(1 for x, y in product(lst1, lst2) if x > y)\n",
    "    lt = sum(1 for x, y in product(lst1, lst2) if x < y)\n",
    "    delta = (gt - lt) / (n1 * n2)\n",
    "    return delta\n",
    "\n",
    "# 계산\n",
    "delta = cliffs_delta(group2, group1)  # group2이 screen, group1이 non-screen\n",
    "print(f\"Cliff's delta: {delta:.4f}\")\n",
    "\n",
    "# 해석 기준 출력 (선택 사항)\n",
    "def interpret_cliffs_delta(delta):\n",
    "    abs_d = abs(delta)\n",
    "    if abs_d < 0.147:\n",
    "        return \"negligible\"\n",
    "    elif abs_d < 0.33:\n",
    "        return \"small\"\n",
    "    elif abs_d < 0.474:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"large\"\n",
    "\n",
    "effect_size = interpret_cliffs_delta(delta)\n",
    "print(f\"Effect size: {effect_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9962a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#시각화\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 기존 TF-IDF 결과 (tfidf_df에는 \"유형\" + 단어들로 구성)\n",
    "# 예: [유형, 여성, 정부, ...]\n",
    "grouped = tfidf_df.groupby(\"유형\").mean().T  # 단어를 인덱스로, 유형을 열로\n",
    "\n",
    "# 상위 중요 단어 추출 (평균 TF-IDF가 높은 단어 기준)\n",
    "top_terms = grouped.mean(axis=1).sort_values(ascending=False).head(30).index\n",
    "top_df = grouped.loc[top_terms]\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(top_df, annot=True, cmap=\"YlGnBu\", fmt=\".3f\")\n",
    "plt.title(\"TF-IDF 단어별 유형 간 비교\")\n",
    "plt.ylabel(\"단어\")\n",
    "plt.xlabel(\"기사 유형\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#완성본\n",
    "\n",
    "# [1] 패키지 불러오기\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import mannwhitneyu, shapiro, levene, ttest_ind\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "from IPython.display import display\n",
    "\n",
    "# [2] 한글 폰트 + 마이너스 깨짐 방지\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# [3] 엑셀 불러오기\n",
    "file_path = r\"C:\\Users\\논문\\3\\.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# [4] Type → media_type 분류\n",
    "def classify_media_type(t):\n",
    "    if t in [1, 2]:\n",
    "        return 'non screen media'\n",
    "    elif t == 3:\n",
    "        return 'screen media'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "df['media_type'] = df['Type'].apply(classify_media_type)\n",
    "\n",
    "# [5] unknown 제거\n",
    "df = df[df['media_type'] != 'unknown']\n",
    "\n",
    "# [6] 그룹별 감성점수 추출\n",
    "non_screen = df[df['media_type'] == 'non screen media']['평균감성점수']\n",
    "screen = df[df['media_type'] == 'screen media']['평균감성점수']\n",
    "\n",
    "# [7] 샘플 수 확인\n",
    "print(f\"\\n샘플 수 - non screen: {len(non_screen)}, screen: {len(screen)}\")\n",
    "\n",
    "# [8] 정규성 검정\n",
    "stat_ns, p_ns = shapiro(non_screen)\n",
    "stat_s, p_s = shapiro(screen)\n",
    "print(\"\\n[정규성 검정 - Shapiro-Wilk]\")\n",
    "print(f\"  non screen media: p = {p_ns:.4f}\")\n",
    "print(f\"  screen media    : p = {p_s:.4f}\")\n",
    "\n",
    "# [9] 등분산성 검정\n",
    "stat_lev, p_lev = levene(non_screen, screen)\n",
    "print(\"\\n[등분산성 검정 - Levene]\")\n",
    "print(f\"  p = {p_lev:.4f}\")\n",
    "\n",
    "# [10] 통계적 비교\n",
    "print(\"\\n[통계적 비교]\")\n",
    "if len(screen) < 10 or len(non_screen) < 10:\n",
    "    stat, p = mannwhitneyu(non_screen, screen, alternative='two-sided')\n",
    "    print(\"  → [샘플 수 적음] Mann-Whitney U test 적용\")\n",
    "elif p_ns > 0.05 and p_s > 0.05:\n",
    "    if p_lev > 0.05:\n",
    "        stat, p = ttest_ind(non_screen, screen, equal_var=True)\n",
    "        print(\"  → Student's t-test 적용\")\n",
    "    else:\n",
    "        stat, p = ttest_ind(non_screen, screen, equal_var=False)\n",
    "        print(\"  → Welch's t-test 적용\")\n",
    "else:\n",
    "    stat, p = mannwhitneyu(non_screen, screen, alternative='two-sided')\n",
    "    print(\"  → Mann-Whitney U test 적용 (정규성 불만족)\")\n",
    "\n",
    "print(f\"  통계량 = {stat:.4f}, p-value = {p:.4f}\")\n",
    "\n",
    "# [11] 통계 요약표\n",
    "summary_table = df.groupby('media_type')['평균감성점수'].agg(\n",
    "    N='count', Mean='mean', Median='median', SD='std', Min='min', Max='max'\n",
    ").reset_index().round(4)\n",
    "\n",
    "display(summary_table)\n",
    "\n",
    "# [12] Boxplot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(data=df, x='media_type', y='평균감성점수')\n",
    "plt.title(\"Boxplot: 평균 감성점수 by Media Type\")\n",
    "plt.xlabel(\"Media Type\")\n",
    "plt.ylabel(\"평균 감성점수\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"boxplot_sentiment.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# [13] Q-Q Plot (non screen)\n",
    "plt.figure(figsize=(6, 4))\n",
    "stats.probplot(non_screen, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q Plot: Non Screen Media\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"qqplot_non_screen.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# [14] Q-Q Plot (screen)\n",
    "plt.figure(figsize=(6, 4))\n",
    "stats.probplot(screen, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q Plot: Screen Media\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"qqplot_screen.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# [15] 결과 저장\n",
    "summary_table.to_excel(\"sentiment_summary_by_type.xlsx\", index=False)\n",
    "print(\"✅ 요약표 저장 완료: sentiment_summary_by_type.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0159e394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
